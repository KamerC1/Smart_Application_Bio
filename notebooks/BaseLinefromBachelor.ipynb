{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa57f6a",
   "metadata": {},
   "source": [
    "### Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + 'data/' + str(patient) + '_week_1sec.csv')\n",
    "\n",
    "magnitude_D = np.sqrt(np.square(df['x_D']) + np.square(df['y_D']) + np.square(df['z_D'])) #mano dominante\n",
    "magnitude_ND = np.sqrt(np.square(df['x_ND']) + np.square(df['y_ND']) + np.square(df['z_ND'])) #mano non dominante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2c04f",
   "metadata": {},
   "source": [
    "### Operations with time-series' magnitude\n",
    "- concatenation\n",
    "- difference (btw domaninat and non dominant)\n",
    "- asymmetrix index (ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elaborate_magnitude(operation_type, magnitude_D, magnitude_ND):\n",
    "\n",
    "    elaborated_magnitude = []\n",
    "\n",
    "    if operation_type == 'concat':\n",
    "        elaborated_magnitude = pd.concat([magnitude_D, magnitude_ND], ignore_index=True)\n",
    "    elif operation_type == 'difference':\n",
    "        elaborated_magnitude = magnitude_D - magnitude_ND\n",
    "    elif operation_type == 'ai':\n",
    "        elaborated_magnitude = (((magnitude_D - magnitude_ND) / (magnitude_D + magnitude_ND)) * 100).fillna(0)\n",
    "    else: \n",
    "        print('operation type non supportata.')\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "    return elaborated_magnitude\n",
    "\n",
    "# Fase di chunking (OPTIONAL)\n",
    "#Need to select a window size\n",
    "\n",
    "    for j in range (0, len(magnitude_D), window_size):\n",
    "\n",
    "        chunk_D = magnitude_D.iloc[j:j + window_size]\n",
    "        chunk_ND = magnitude_ND.iloc[j:j + window_size]\n",
    "\n",
    "        if chunk_D.size == window_size and chunk_ND.size == window_size:\n",
    "            \n",
    "            for es in estimators:\n",
    "                es['series'].append(elaborate_magnitude(es['method'], chunk_D, chunk_ND))\n",
    "\n",
    "            if chunk_D.agg('sum') == 0 and chunk_ND.agg('sum') == 0:\n",
    "                to_discard.append(int(j/window_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ebe48",
   "metadata": {},
   "source": [
    "### Preprocessing starting from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2385c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nella tesi di triennale non fanno un cazzo di pre-processing, prendono direttamente x, y, z dalle time-series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e607e87",
   "metadata": {},
   "source": [
    "### Correlation analysis\n",
    "\n",
    "- correlation btw WEEK sessions and Clinical sessions (1h) --> sliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30945ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nella tesi di triennale usano semplicemente corrcoef ma cos√¨ non fai sliding\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
